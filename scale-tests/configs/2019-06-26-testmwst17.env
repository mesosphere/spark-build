# Depends on:
# - TEST_NAME
# - TEST_S3_BUCKET
# - TEST_S3_FOLDER

# Notes:
#
# When this test was run (2019-06-26), soak114s had 61 agents in total:
# - 49 private agents with 4 CPUs, 14GB MEM and 245GB disk
# -  8 private agents with 8 CPUs, 30GB MEM and 1.4TB disk
# -  1 private agents with 4 CPUs, 58GB MEM and 290GB disk and 1 GPU
# -  3 public agents with 4 CPUs, 14GB MEM and 245GB disk

# Cluster configuration ########################################################
# Total CPU quota: 50
# Total MEM quota: 130000

CLUSTER_URL="https://soak114s.testing.mesosphe.re"
SECURITY="strict"

# Test configuration ###########################################################

SHOULD_INSTALL_INFRASTRUCTURE=true
SHOULD_INSTALL_NON_GPU_DISPATCHERS=true
SHOULD_INSTALL_GPU_DISPATCHERS=true
SHOULD_RUN_FAILING_STREAMING_JOBS=false
SHOULD_RUN_FINITE_STREAMING_JOBS=true
SHOULD_RUN_INFINITE_STREAMING_JOBS=true
SHOULD_RUN_BATCH_JOBS=true
SHOULD_RUN_GPU_BATCH_JOBS=false
SHOULD_UNINSTALL_INFRASTRUCTURE_AT_THE_END=false

# Infrastructure configuration #################################################

SERVICE_NAMES_PREFIX="${TEST_NAME}/"
INFRASTRUCTURE_OUTPUT_FILE="infrastructure.json"
KAFKA_ZOOKEEPER_CONFIG='scale-tests/configs/kafka-zookeeper-options.json'
KAFKA_CLUSTER_COUNT=1
KAFKA_CONFIG='scale-tests/configs/kafka-options.json'
CASSANDRA_CLUSTER_COUNT=1
CASSANDRA_CONFIG='scale-tests/configs/cassandra-options.json'

# Spark configuration ##########################################################

# Note: leaving the Spark executor Docker image empty so that
# executors inherit the image used for dispatchers.
SPARK_EXECUTOR_DOCKER_IMAGE=

# Spark 2.8.0-2.4.0 from the Universe.
SPARK_PACKAGE_REPO=

# Non-GPU dispatchers configuration ############################################
# CPU quota: 48
# MEM quota: 120000

NON_GPU_NUM_DISPATCHERS=3
NON_GPU_DISPATCHERS_OUTPUT_FILE="non-gpu-dispatchers.out"
NON_GPU_DISPATCHERS_JSON_OUTPUT_FILE="${NON_GPU_DISPATCHERS_OUTPUT_FILE}-dispatchers.json" # NOTE: this name is built internally by the deploy-dispatchers.py script.
NON_GPU_QUOTA_DRIVERS_CPUS=8
NON_GPU_QUOTA_DRIVERS_MEM=20000
NON_GPU_QUOTA_EXECUTORS_CPUS=8
NON_GPU_QUOTA_EXECUTORS_MEM=20000

# GPU dispatchers configuration ################################################
# CPU quota: 4
# MEM quota: 50000

GPU_NUM_DISPATCHERS=1
GPU_DISPATCHERS_OUTPUT_FILE="gpu-dispatchers.out"
GPU_DISPATCHERS_JSON_OUTPUT_FILE="${GPU_DISPATCHERS_OUTPUT_FILE}-dispatchers.json" # NOTE: this name is built internally by the deploy-dispatchers.py script.
GPU_QUOTA_DRIVERS_CPUS=2
GPU_QUOTA_DRIVERS_MEM=10000
GPU_QUOTA_DRIVERS_GPUS=
GPU_QUOTA_EXECUTORS_CPUS=
GPU_QUOTA_EXECUTORS_MEM=
GPU_QUOTA_EXECUTORS_GPUS=
# NOTE: to test Core teamâ€™s hypothesis of GPU quota negatively impacting spark
# launch rates, we remove the GPU quota entirely from all executor roles.
GPU_REMOVE_EXECUTORS_ROLES_QUOTAS=true

# Common streaming jobs configuration ##########################################

TEST_ASSEMBLY_JAR_URL='http://infinity-artifacts.s3.amazonaws.com/scale-tests/dcos-spark-scala-tests-assembly-2.4.0-20190325.jar'
NUM_DISPATCHERS="$((${NON_GPU_NUM_DISPATCHERS} + ${GPU_NUM_DISPATCHERS}))"
DISPATCHERS_JSON_OUTPUT_FILE="all-dispatchers.json"

# Failing streaming jobs configuration #########################################

FAILING_SUBMISSIONS_OUTPUT_FILE="failing-submissions.out"
FAILING_NUM_PRODUCERS_PER_KAFKA="${NON_GPU_NUM_DISPATCHERS}"
FAILING_NUM_CONSUMERS_PER_PRODUCER=1
FAILING_PRODUCER_NUMBER_OF_WORDS=7692
FAILING_PRODUCER_WORDS_PER_SECOND=1
FAILING_PRODUCER_SPARK_CORES_MAX=2
FAILING_PRODUCER_SPARK_EXECUTOR_CORES=2
FAILING_CONSUMER_BATCH_SIZE_SECONDS=10
FAILING_CONSUMER_SPARK_CORES_MAX=1
FAILING_CONSUMER_SPARK_EXECUTOR_CORES=1

# Finite streaming jobs configuration ##########################################

FINITE_SUBMISSIONS_OUTPUT_FILE="finite-submissions.out"
FINITE_NUM_PRODUCERS_PER_KAFKA="${NON_GPU_NUM_DISPATCHERS}"
FINITE_NUM_CONSUMERS_PER_PRODUCER=1
FINITE_PRODUCER_NUMBER_OF_WORDS=7692
FINITE_PRODUCER_WORDS_PER_SECOND=1
FINITE_PRODUCER_SPARK_CORES_MAX=2
FINITE_PRODUCER_SPARK_EXECUTOR_CORES=2
FINITE_CONSUMER_BATCH_SIZE_SECONDS=10
FINITE_CONSUMER_SPARK_CORES_MAX=1
FINITE_CONSUMER_SPARK_EXECUTOR_CORES=1

# Infinite streaming jobs configuration ########################################

INFINITE_SUBMISSIONS_OUTPUT_FILE="infinite-submissions.out"
INFINITE_NUM_PRODUCERS_PER_KAFKA="${NON_GPU_NUM_DISPATCHERS}"
INFINITE_NUM_CONSUMERS_PER_PRODUCER=1
INFINITE_PRODUCER_NUMBER_OF_WORDS=0
INFINITE_PRODUCER_WORDS_PER_SECOND=1
INFINITE_PRODUCER_SPARK_CORES_MAX=2
INFINITE_PRODUCER_SPARK_EXECUTOR_CORES=2
INFINITE_CONSUMER_BATCH_SIZE_SECONDS=10
INFINITE_CONSUMER_SPARK_CORES_MAX=1
INFINITE_CONSUMER_SPARK_EXECUTOR_CORES=1

# Batch jobs configuration #####################################################

NON_GPU_DISPATCHERS_JSON_OUTPUT_FILE_URL="https://${TEST_S3_BUCKET}.s3.amazonaws.com/${TEST_S3_FOLDER}/${NON_GPU_DISPATCHERS_JSON_OUTPUT_FILE}"

BATCH_APP_ID="/${SERVICE_NAMES_PREFIX}batch-workload"
BATCH_SCRIPT_CPUS=2
BATCH_SCRIPT_MEM=8192
BATCH_SUBMITS_PER_MIN=1
BATCH_SPARK_BUILD_BRANCH=master

# Batch GPU jobs configuration #################################################

GPU_DISPATCHERS_JSON_OUTPUT_FILE_URL="https://${TEST_S3_BUCKET}.s3.amazonaws.com/${TEST_S3_FOLDER}/${GPU_DISPATCHERS_JSON_OUTPUT_FILE}"

GPU_APP_ID="/${SERVICE_NAMES_PREFIX}gpu-batch-workload"
GPU_SCRIPT_CPUS=2
GPU_SCRIPT_MEM=4096
GPU_DOCKER_IMAGE='samvantran/spark-dcos-gpu:metrics'
GPU_SUBMITS_PER_MIN=1
GPU_MAX_NUM_DISPATCHERS=${GPU_NUM_DISPATCHERS}
GPU_SPARK_CORES_MAX=2
GPU_SPARK_MESOS_EXECUTOR_GPUS=1
GPU_SPARK_MESOS_MAX_GPUS=1
GPU_SPARK_BUILD_BRANCH=master
