# Depends on:
# - TEST_NAME
# - TEST_S3_BUCKET
# - TEST_S3_FOLDER

# Notes:
#   - mwt20.scaletesting.mesosphe.re:
#     - 196 public agents
#       - 64 CPUs and 479.1 GB MEM each
#     - total 12544 CPUs and 93904 GB MEM

# Workload configuration #######################################################
# Total CPU quota: 2330
# Total MEM quota: 5500000

# CPU quota limit to set for Marathon group: 2400
# MEM quota limit to set for Marathon group: 6000000

CLUSTER_URL="https://mwt20.scaletesting.mesosphe.re"
SECURITY="strict"

# Test configuration ###########################################################

SHOULD_INSTALL_INFRASTRUCTURE=true
SHOULD_INSTALL_NON_GPU_DISPATCHERS=true
SHOULD_INSTALL_GPU_DISPATCHERS=true
SHOULD_RUN_FAILING_STREAMING_JOBS=false
SHOULD_RUN_FINITE_STREAMING_JOBS=true
SHOULD_RUN_INFINITE_STREAMING_JOBS=true
SHOULD_RUN_BATCH_JOBS=true
SHOULD_RUN_GPU_BATCH_JOBS=true
SHOULD_UNINSTALL_INFRASTRUCTURE_AT_THE_END=false

# Infrastructure configuration #################################################

ROLE_NAME="${TEST_NAME}"
GROUP_NAME="/${ROLE_NAME}"

SERVICE_NAMES_PREFIX="${TEST_NAME}/"
INFRASTRUCTURE_OUTPUT_FILE="infrastructure.json"

KAFKA_CLUSTER_COUNT=1
CASSANDRA_CLUSTER_COUNT=1

KAFKA_ZOOKEEPER_CONFIG='scale-tests/configs/kafka-zookeeper-options.json'
KAFKA_CONFIG='scale-tests/configs/kafka-options.json'
CASSANDRA_CONFIG='scale-tests/configs/cassandra-options.json'
SPARK_CONFIG='scale-tests/configs/spark-options.json'

# Spark configuration ##########################################################

# Note: leaving the Spark executor Docker image empty so that
# executors inherit the image used for dispatchers.
SPARK_EXECUTOR_DOCKER_IMAGE=

# Service package repositories #################################################
# Empty values will default to latest Universe packages ########################

ZOOKEEPER_PACKAGE_REPO="https://universe-converter.mesosphere.com/transform?url=https://infinity-artifacts.s3.amazonaws.com/permanent/confluent-zookeeper/assets/2.6.1-5.1.2e/stub-universe-confluent-zookeeper.json"

KAFKA_PACKAGE_REPO="https://universe-converter.mesosphere.com/transform?url=https://infinity-artifacts.s3.amazonaws.com/permanent/confluent-kafka/assets/2.7.1-5.3.0/stub-universe-confluent-kafka.json"

CASSANDRA_PACKAGE_REPO="https://universe-converter.mesosphere.com/transform?url=https://infinity-artifacts.s3.amazonaws.com/permanent/cassandra/assets/2.7.0-3.11.4/stub-universe-cassandra.json"

# We used a Spark ephemeral stub that added a few fixes related to TLS handling.
# It should have been functionally equivalent to Spark 2.12.0-3.0.1.
SPARK_PACKAGE_REPO=

# Non-GPU dispatchers configuration ############################################

# Total quota:
# - driver:
#   - 1000 cpus
#   - 2500000 mem
# - executor:
#   - 1250 cpus
#   - 2000000 mem

NON_GPU_NUM_DISPATCHERS=50
NON_GPU_DISPATCHERS_OUTPUT_FILE="non-gpu-dispatchers.out"
NON_GPU_DISPATCHERS_JSON_OUTPUT_FILE="${NON_GPU_DISPATCHERS_OUTPUT_FILE}-dispatchers.json" # NOTE: this name is built internally by the deploy-dispatchers.py script.
NON_GPU_QUOTA_DRIVERS_CPUS=20
NON_GPU_QUOTA_DRIVERS_MEM=50000
NON_GPU_QUOTA_EXECUTORS_CPUS=25
NON_GPU_QUOTA_EXECUTORS_MEM=40000

# GPU dispatchers configuration ################################################

# Total quota:
# - driver:
#   - 80 cpus
#   - 1000000 mem
#   - 0 gpus
# - executor:
#   - 0 cpus
#   - 0 mem
#   - 0 gpus

GPU_NUM_DISPATCHERS=5
GPU_DISPATCHERS_OUTPUT_FILE="gpu-dispatchers.out"
GPU_DISPATCHERS_JSON_OUTPUT_FILE="${GPU_DISPATCHERS_OUTPUT_FILE}-dispatchers.json" # NOTE: this name is built internally by the deploy-dispatchers.py script.
GPU_QUOTA_DRIVERS_CPUS=16
GPU_QUOTA_DRIVERS_MEM=200000
GPU_QUOTA_DRIVERS_GPUS=
GPU_QUOTA_EXECUTORS_CPUS=
GPU_QUOTA_EXECUTORS_MEM=
GPU_QUOTA_EXECUTORS_GPUS=
# NOTE: don't remove role quotas because everything is being deployed with the
# same group role.
GPU_REMOVE_EXECUTORS_ROLES_QUOTAS=false

# Common streaming jobs configuration ##########################################

TEST_ASSEMBLY_JAR_URL='http://infinity-artifacts.s3.amazonaws.com/scale-tests/dcos-spark-scala-tests-assembly-2.4.0-20190325.jar'
NUM_DISPATCHERS="$((${NON_GPU_NUM_DISPATCHERS} + ${GPU_NUM_DISPATCHERS}))"
DISPATCHERS_JSON_OUTPUT_FILE="all-dispatchers.json"

# Failing streaming jobs configuration #########################################

FAILING_SUBMISSIONS_OUTPUT_FILE="failing-submissions.out"
FAILING_NUM_PRODUCERS_PER_KAFKA="${NON_GPU_NUM_DISPATCHERS}"
FAILING_NUM_CONSUMERS_PER_PRODUCER=1
FAILING_PRODUCER_NUMBER_OF_WORDS=7692
FAILING_PRODUCER_WORDS_PER_SECOND=1
FAILING_PRODUCER_SPARK_CORES_MAX=2
FAILING_PRODUCER_SPARK_EXECUTOR_CORES=2
FAILING_CONSUMER_BATCH_SIZE_SECONDS=10
FAILING_CONSUMER_SPARK_CORES_MAX=1
FAILING_CONSUMER_SPARK_EXECUTOR_CORES=1

# Finite streaming jobs configuration ##########################################

FINITE_SUBMISSIONS_OUTPUT_FILE="finite-submissions.out"
FINITE_NUM_PRODUCERS_PER_KAFKA="${NON_GPU_NUM_DISPATCHERS}" # 1 Kafka and 50 dispatchers -> 50 producers.
FINITE_NUM_CONSUMERS_PER_PRODUCER=1 # 50 producers -> 50 consumers.
# 50 producers + 50 consumers = 100 total finite streaming jobs
FINITE_PRODUCER_NUMBER_OF_WORDS=7692
FINITE_PRODUCER_WORDS_PER_SECOND=1
# 7692 words / 1 word per second -> ~2h runtime.
FINITE_PRODUCER_SPARK_CORES_MAX=2
FINITE_PRODUCER_SPARK_EXECUTOR_CORES=2
FINITE_CONSUMER_BATCH_SIZE_SECONDS=10
FINITE_CONSUMER_SPARK_CORES_MAX=1
FINITE_CONSUMER_SPARK_EXECUTOR_CORES=1

# Infinite streaming jobs configuration ########################################

INFINITE_SUBMISSIONS_OUTPUT_FILE="infinite-submissions.out"
INFINITE_NUM_PRODUCERS_PER_KAFKA="${NON_GPU_NUM_DISPATCHERS}" # 1 Kafka and 50 dispatchers -> 50 producers.
INFINITE_NUM_CONSUMERS_PER_PRODUCER=1 # 50 producers -> 50 consumers.
# 50 producers + 50 consumers = 100 total infinite streaming jobs
INFINITE_PRODUCER_NUMBER_OF_WORDS=0
INFINITE_PRODUCER_WORDS_PER_SECOND=1
INFINITE_PRODUCER_SPARK_CORES_MAX=2
INFINITE_PRODUCER_SPARK_EXECUTOR_CORES=2
INFINITE_CONSUMER_BATCH_SIZE_SECONDS=10
INFINITE_CONSUMER_SPARK_CORES_MAX=1
INFINITE_CONSUMER_SPARK_EXECUTOR_CORES=1

# Batch jobs configuration #####################################################

NON_GPU_DISPATCHERS_JSON_OUTPUT_FILE_URL="https://${TEST_S3_BUCKET}.s3.amazonaws.com/${TEST_S3_FOLDER}/${NON_GPU_DISPATCHERS_JSON_OUTPUT_FILE}"

BATCH_APP_ID="/${SERVICE_NAMES_PREFIX}batch-workload"
BATCH_SCRIPT_CPUS=6
BATCH_SCRIPT_MEM=12288
BATCH_SUBMITS_PER_MIN=13
BATCH_SPARK_BUILD_BRANCH=mwt-20

# Batch GPU jobs configuration #################################################

GPU_DISPATCHERS_JSON_OUTPUT_FILE_URL="https://${TEST_S3_BUCKET}.s3.amazonaws.com/${TEST_S3_FOLDER}/${GPU_DISPATCHERS_JSON_OUTPUT_FILE}"

GPU_APP_ID="/${SERVICE_NAMES_PREFIX}gpu-batch-workload"
GPU_SCRIPT_CPUS=2
GPU_SCRIPT_MEM=4096
GPU_DOCKER_IMAGE='samvantran/spark-dcos-gpu:metrics'
GPU_SUBMITS_PER_MIN=5
GPU_MAX_NUM_DISPATCHERS=${GPU_NUM_DISPATCHERS}
GPU_SPARK_CORES_MAX=4
GPU_SPARK_MESOS_EXECUTOR_GPUS=4
GPU_SPARK_MESOS_MAX_GPUS=4
GPU_SPARK_BUILD_BRANCH=master
