# Depends on:
# - TEST_NAME
# - TEST_S3_BUCKET
# - TEST_S3_FOLDER

# Infrastructure configuration #################################################

SERVICE_NAMES_PREFIX="${TEST_NAME}/"
INFRASTRUCTURE_OUTPUT_FILE="${TEST_NAME}-infrastructure.json"
KAFKA_ZOOKEEPER_CONFIG='scale-tests/configs/kafka-zookeeper-options.json'
KAFKA_CLUSTER_COUNT=1
KAFKA_CONFIG='scale-tests/configs/kafka-options.json'
CASSANDRA_CLUSTER_COUNT=1
CASSANDRA_CONFIG='scale-tests/configs/cassandra-options.json'

# Non-GPU dispatchers configuration ############################################

NON_GPU_NUM_DISPATCHERS=10
NON_GPU_DISPATCHERS_OUTPUT_FILE="${TEST_NAME}-non-gpu-dispatchers-${NON_GPU_NUM_DISPATCHERS}.out"
NON_GPU_DISPATCHERS_JSON_OUTPUT_FILE="${NON_GPU_DISPATCHERS_OUTPUT_FILE}-dispatchers.json" # NOTE: this name is set internally by the deploy dispatchers script
NON_GPU_QUOTA_DRIVERS_CPUS=20
NON_GPU_QUOTA_DRIVERS_MEM=50000
NON_GPU_QUOTA_EXECUTORS_CPUS=25
NON_GPU_QUOTA_EXECUTORS_MEM=40000

# GPU dispatchers configuration ################################################

GPU_NUM_DISPATCHERS=2
GPU_DISPATCHERS_OUTPUT_FILE="${TEST_NAME}-gpu-dispatchers-${GPU_NUM_DISPATCHERS}.out"
GPU_DISPATCHERS_JSON_OUTPUT_FILE="${GPU_DISPATCHERS_OUTPUT_FILE}-dispatchers.json" # NOTE: this name is set internally by the deploy dispatchers script
GPU_QUOTA_DRIVERS_CPUS=16
GPU_QUOTA_DRIVERS_MEM=200000
GPU_QUOTA_EXECUTORS_CPUS=
GPU_QUOTA_EXECUTORS_MEM=
GPU_QUOTA_EXECUTORS_GPUS=
# NOTE: to test Core teamâ€™s hypothesis of GPU quota negatively impacting spark
# launch rates, we remove the GPU quota entirely from all executor roles.
GPU_REMOVE_EXECUTORS_ROLES_QUOTAS=true

# Common streaming jobs configuration ##########################################

TEST_ASSEMBLY_JAR_URL='http://infinity-artifacts.s3.amazonaws.com/scale-tests/dcos-spark-scala-tests-assembly-20180612-5fa9420.jar'
NUM_DISPATCHERS="$((${NON_GPU_NUM_DISPATCHERS} + ${GPU_NUM_DISPATCHERS}))"
DISPATCHERS_JSON_OUTPUT_FILE="${TEST_NAME}-all-dispatchers-${NUM_DISPATCHERS}.json"

# Failing streaming jobs configuration #########################################

FAILING_SUBMISSIONS_OUTPUT_FILE="${TEST_NAME}-failing-submissions.out"
FAILING_NUM_PRODUCERS_PER_KAFKA="${NUM_DISPATCHERS}"
FAILING_NUM_CONSUMERS_PER_PRODUCER=1
# Should have been 7692 for 2 hour runtime
FAILING_PRODUCER_NUMBER_OF_WORDS=1300000
FAILING_PRODUCER_WORDS_PER_SECOND=1
FAILING_PRODUCER_SPARK_CORES_MAX=2
FAILING_PRODUCER_SPARK_EXECUTOR_CORES=2
FAILING_CONSUMER_BATCH_SIZE_SECONDS=10
FAILING_CONSUMER_SPARK_CORES_MAX=1
FAILING_CONSUMER_SPARK_EXECUTOR_CORES=1

# Finite streaming jobs configuration ##########################################

FINITE_SUBMISSIONS_OUTPUT_FILE="${TEST_NAME}-finite-submissions.out"
# 1 Kafka * 10 non-GPU dispatchers / 2 -> 5 finite producers.
FINITE_NUM_PRODUCERS_PER_KAFKA=$((${NON_GPU_NUM_DISPATCHERS} / 2))
# 5 finite producers * 5 -> 25 finite consumers.
FINITE_NUM_CONSUMERS_PER_PRODUCER=5
# Each word is approximately 10 bytes.
# 10^6 words * 10 bytes -> 10^7 bytes total -> 10 MB per producer
#   -> 100 MB total Kafka ingress
#   -> 500 MB total Kafka egress
FINITE_PRODUCER_NUMBER_OF_WORDS=$((10**8))
# Should have been 10**4 for 2 hour runtime
# ~10^8~ words / 1 words per second -> 166 minutes runtime.
# 100 words per second
#   -> 1 KB per second per producer -> 5 KB per second Kafka ingress
#   -> 1 KB per second per consumer -> 25 KB per second Kafka egress
FINITE_PRODUCER_WORDS_PER_SECOND=1
FINITE_PRODUCER_SPARK_CORES_MAX=2
FINITE_PRODUCER_SPARK_EXECUTOR_CORES=2
FINITE_CONSUMER_BATCH_SIZE_SECONDS=10
FINITE_CONSUMER_SPARK_CORES_MAX=1
FINITE_CONSUMER_SPARK_EXECUTOR_CORES=1

# Infinite streaming jobs configuration ########################################

INFINITE_SUBMISSIONS_OUTPUT_FILE="${TEST_NAME}-infinite-submissions.out"
# 1 Kafka * 10 non-GPU dispatchers -> 5 infinite producers.
INFINITE_NUM_PRODUCERS_PER_KAFKA=$((${NON_GPU_NUM_DISPATCHERS} / 2))
# 5 infinite producers * 5 -> 25 infinite consumers.
INFINITE_NUM_CONSUMERS_PER_PRODUCER=5
# Each word is approximately 10 bytes.
# 0 -> infinite.
INFINITE_PRODUCER_NUMBER_OF_WORDS=0
# 1    words per second per producer
#   -> 10 B per second per producer -> 50 B per second Kafka ingress
#   -> 10 B per second per consumer -> 250 B per second Kafka egress
INFINITE_PRODUCER_WORDS_PER_SECOND=1
INFINITE_PRODUCER_SPARK_CORES_MAX=2
INFINITE_PRODUCER_SPARK_EXECUTOR_CORES=2
INFINITE_CONSUMER_BATCH_SIZE_SECONDS=10
INFINITE_CONSUMER_SPARK_CORES_MAX=1
INFINITE_CONSUMER_SPARK_EXECUTOR_CORES=1

# Batch jobs configuration #####################################################

NON_GPU_DISPATCHERS_JSON_OUTPUT_FILE_URL="https://${TEST_S3_BUCKET}.s3.amazonaws.com/${TEST_S3_FOLDER}/${NON_GPU_DISPATCHERS_JSON_OUTPUT_FILE}"

BATCH_APP_ID="/${SERVICE_NAMES_PREFIX}batch-workload"
BATCH_SCRIPT_CPUS=2
BATCH_SCRIPT_MEM=4096
BATCH_SUBMITS_PER_MIN=2
BATCH_SPARK_BUILD_BRANCH=master

# Batch GPU jobs configuration #################################################

GPU_DISPATCHERS_JSON_OUTPUT_FILE_URL="https://${TEST_S3_BUCKET}.s3.amazonaws.com/${TEST_S3_FOLDER}/${GPU_DISPATCHERS_JSON_OUTPUT_FILE}"

GPU_APP_ID="/${SERVICE_NAMES_PREFIX}gpu-batch-workload"
GPU_SCRIPT_CPUS=2
GPU_SCRIPT_MEM=4096
GPU_DOCKER_IMAGE='samvantran/spark-dcos-gpu:metrics'
GPU_SUBMITS_PER_MIN=2
GPU_MAX_NUM_DISPATCHERS=2
GPU_SPARK_CORES_MAX=4
GPU_SPARK_MESOS_EXECUTOR_GPUS=4
GPU_SPARK_MESOS_MAX_GPUS=4
GPU_SPARK_BUILD_BRANCH=master
