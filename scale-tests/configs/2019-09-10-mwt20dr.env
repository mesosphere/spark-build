# Depends on:
# - TEST_NAME
# - TEST_S3_BUCKET
# - TEST_S3_FOLDER

# Notes:
#   mwtdr20.scaletesting.mesosphe.re
#   - 10 public agents with 64 CPUs and 479.1 GB MEM each
#   - 1 public agents with 64 CPUs and 479.1 GB MEM
#   - total 704 CPUs and 5270 GB MEM

# Workload configuration #######################################################
# Total CPU quota: 34
# Total MEM quota: 90000

# CPU quota limit to set for Marathon group: 40 CPUs
# MEM quota limit to set for Marathon group: 100000 MB MEM

CLUSTER_URL="https://mwtdr20.scaletesting.mesosphe.re"
SECURITY="strict"

# Test configuration ###########################################################

SHOULD_INSTALL_INFRASTRUCTURE=true
SHOULD_INSTALL_NON_GPU_DISPATCHERS=true
SHOULD_INSTALL_GPU_DISPATCHERS=true
SHOULD_RUN_FAILING_STREAMING_JOBS=false
SHOULD_RUN_FINITE_STREAMING_JOBS=true
SHOULD_RUN_INFINITE_STREAMING_JOBS=true
SHOULD_RUN_BATCH_JOBS=true
SHOULD_RUN_GPU_BATCH_JOBS=false
SHOULD_UNINSTALL_INFRASTRUCTURE_AT_THE_END=false

# Infrastructure configuration #################################################

GROUP_NAME="/${TEST_NAME}"
SERVICE_NAMES_PREFIX="${TEST_NAME}/"
INFRASTRUCTURE_OUTPUT_FILE="infrastructure.json"
KAFKA_ZOOKEEPER_CONFIG='scale-tests/configs/kafka-zookeeper-options.json'
KAFKA_CLUSTER_COUNT=1
KAFKA_CONFIG='scale-tests/configs/kafka-options.json'
CASSANDRA_CLUSTER_COUNT=1
CASSANDRA_CONFIG='scale-tests/configs/cassandra-options.json'

# Spark configuration ##########################################################

# Note: leaving the Spark executor Docker image empty so that
# executors inherit the image used for dispatchers.
SPARK_EXECUTOR_DOCKER_IMAGE=

# Service package repositories #################################################
# Empty values will default to latest Universe packages ########################

ZOOKEEPER_PACKAGE_REPO="https://universe-converter.mesosphere.com/transform?url=https://infinity-artifacts.s3.amazonaws.com/permanent/confluent-zookeeper/assets/2.6.1-5.1.2e/stub-universe-confluent-zookeeper.json"

KAFKA_PACKAGE_REPO="https://universe-converter.mesosphere.com/transform?url=https://infinity-artifacts.s3.amazonaws.com/permanent/confluent-kafka/assets/2.7.1-5.3.0/stub-universe-confluent-kafka.json"

CASSANDRA_PACKAGE_REPO="https://universe-converter.mesosphere.com/transform?url=https://infinity-artifacts.s3.amazonaws.com/permanent/cassandra/assets/2.7.0-3.11.4/stub-universe-cassandra.json"

# We used a Spark ephemeral stub that added a few fixes related to TLS handling.
# It should have been functionally equivalent to Spark 2.10.0-2.4.5.
SPARK_PACKAGE_REPO=

# Non-GPU dispatchers configuration ############################################

NON_GPU_NUM_DISPATCHERS=2
NON_GPU_DISPATCHERS_OUTPUT_FILE="non-gpu-dispatchers.out"
NON_GPU_DISPATCHERS_JSON_OUTPUT_FILE="${NON_GPU_DISPATCHERS_OUTPUT_FILE}-dispatchers.json" # NOTE: this name is built internally by the deploy-dispatchers.py script.
NON_GPU_QUOTA_DRIVERS_CPUS=8
NON_GPU_QUOTA_DRIVERS_MEM=20000
NON_GPU_QUOTA_EXECUTORS_CPUS=8
NON_GPU_QUOTA_EXECUTORS_MEM=20000

# GPU dispatchers configuration ################################################
# CPU quota: 4
# MEM quota: 50000

GPU_NUM_DISPATCHERS=1
GPU_DISPATCHERS_OUTPUT_FILE="gpu-dispatchers.out"
GPU_DISPATCHERS_JSON_OUTPUT_FILE="${GPU_DISPATCHERS_OUTPUT_FILE}-dispatchers.json" # NOTE: this name is built internally by the deploy-dispatchers.py script.
GPU_QUOTA_DRIVERS_CPUS=2
GPU_QUOTA_DRIVERS_MEM=10000
GPU_QUOTA_DRIVERS_GPUS=
GPU_QUOTA_EXECUTORS_CPUS=
GPU_QUOTA_EXECUTORS_MEM=
GPU_QUOTA_EXECUTORS_GPUS=
# NOTE: to test Core teamâ€™s hypothesis of GPU quota negatively impacting spark
# launch rates, we remove the GPU quota entirely from all executor roles.
GPU_REMOVE_EXECUTORS_ROLES_QUOTAS=true

# Common streaming jobs configuration ##########################################

TEST_ASSEMBLY_JAR_URL='http://infinity-artifacts.s3.amazonaws.com/scale-tests/dcos-spark-scala-tests-assembly-2.4.0-20190325.jar'
NUM_DISPATCHERS="$((${NON_GPU_NUM_DISPATCHERS} + ${GPU_NUM_DISPATCHERS}))"
DISPATCHERS_JSON_OUTPUT_FILE="all-dispatchers.json"

# Failing streaming jobs configuration #########################################

FAILING_SUBMISSIONS_OUTPUT_FILE="failing-submissions.out"
FAILING_NUM_PRODUCERS_PER_KAFKA="${NON_GPU_NUM_DISPATCHERS}"
FAILING_NUM_CONSUMERS_PER_PRODUCER=1
FAILING_PRODUCER_NUMBER_OF_WORDS=7692
FAILING_PRODUCER_WORDS_PER_SECOND=1
FAILING_PRODUCER_SPARK_CORES_MAX=2
FAILING_PRODUCER_SPARK_EXECUTOR_CORES=2
FAILING_CONSUMER_BATCH_SIZE_SECONDS=10
FAILING_CONSUMER_SPARK_CORES_MAX=1
FAILING_CONSUMER_SPARK_EXECUTOR_CORES=1

# Finite streaming jobs configuration ##########################################

FINITE_SUBMISSIONS_OUTPUT_FILE="finite-submissions.out"
FINITE_NUM_PRODUCERS_PER_KAFKA="${NON_GPU_NUM_DISPATCHERS}"
FINITE_NUM_CONSUMERS_PER_PRODUCER=1
FINITE_PRODUCER_NUMBER_OF_WORDS=7692
FINITE_PRODUCER_WORDS_PER_SECOND=1
FINITE_PRODUCER_SPARK_CORES_MAX=2
FINITE_PRODUCER_SPARK_EXECUTOR_CORES=2
FINITE_CONSUMER_BATCH_SIZE_SECONDS=10
FINITE_CONSUMER_SPARK_CORES_MAX=1
FINITE_CONSUMER_SPARK_EXECUTOR_CORES=1

# Infinite streaming jobs configuration ########################################

INFINITE_SUBMISSIONS_OUTPUT_FILE="infinite-submissions.out"
INFINITE_NUM_PRODUCERS_PER_KAFKA="${NON_GPU_NUM_DISPATCHERS}"
INFINITE_NUM_CONSUMERS_PER_PRODUCER=1
INFINITE_PRODUCER_NUMBER_OF_WORDS=0
INFINITE_PRODUCER_WORDS_PER_SECOND=1
INFINITE_PRODUCER_SPARK_CORES_MAX=2
INFINITE_PRODUCER_SPARK_EXECUTOR_CORES=2
INFINITE_CONSUMER_BATCH_SIZE_SECONDS=10
INFINITE_CONSUMER_SPARK_CORES_MAX=1
INFINITE_CONSUMER_SPARK_EXECUTOR_CORES=1

# Batch jobs configuration #####################################################

NON_GPU_DISPATCHERS_JSON_OUTPUT_FILE_URL="https://${TEST_S3_BUCKET}.s3.amazonaws.com/${TEST_S3_FOLDER}/${NON_GPU_DISPATCHERS_JSON_OUTPUT_FILE}"

BATCH_APP_ID="/${SERVICE_NAMES_PREFIX}batch-workload"
BATCH_SCRIPT_CPUS=2
BATCH_SCRIPT_MEM=8192
BATCH_SUBMITS_PER_MIN=1
BATCH_SPARK_BUILD_BRANCH=master

# Batch GPU jobs configuration #################################################

GPU_DISPATCHERS_JSON_OUTPUT_FILE_URL="https://${TEST_S3_BUCKET}.s3.amazonaws.com/${TEST_S3_FOLDER}/${GPU_DISPATCHERS_JSON_OUTPUT_FILE}"

GPU_APP_ID="/${SERVICE_NAMES_PREFIX}gpu-batch-workload"
GPU_SCRIPT_CPUS=2
GPU_SCRIPT_MEM=4096
GPU_DOCKER_IMAGE='samvantran/spark-dcos-gpu:metrics'
GPU_SUBMITS_PER_MIN=1
GPU_MAX_NUM_DISPATCHERS=${GPU_NUM_DISPATCHERS}
GPU_SPARK_CORES_MAX=2
GPU_SPARK_MESOS_EXECUTOR_GPUS=1
GPU_SPARK_MESOS_MAX_GPUS=1
GPU_SPARK_BUILD_BRANCH=master
